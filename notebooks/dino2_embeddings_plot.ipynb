{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from img2vec_dino2 import Img2VecResnet18\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.patches import Ellipse\n",
    "import glob\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROPS_PATH = \"../data/knowledge_base/crops/object/\"\n",
    "IMG_PATH = \"../data/img/cocacola_bottle.jpeg\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images on the scatter plot\n",
    "def show_images(x, y, imagenes, ax):\n",
    "    for i in range(len(imagenes)):\n",
    "        # Create an image box for each image using OffsetImage\n",
    "        image_box = OffsetImage(imagenes[i], zoom=0.6)\n",
    "\n",
    "        # Create an annotation box for each image at the corresponding coordinates\n",
    "        ab = AnnotationBbox(image_box, (x[i], y[i]), frameon=False)\n",
    "\n",
    "        # Add the annotation box to the plot\n",
    "        ax.add_artist(ab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"facebook/dinov2-base\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "def get_dino_embedding(image_path: str):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        emb = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "        emb = torch.nn.functional.normalize(emb, dim=-1)\n",
    "    return emb.squeeze().cpu().numpy()\n",
    "\n",
    "image_paths = glob.glob(f\"{CROPS_PATH}/**/*.jpg\")\n",
    "\n",
    "# Ejemplo: obtener embeddings de todas las im√°genes\n",
    "embeddings = []\n",
    "for path in image_paths:\n",
    "    emb = get_dino_embedding(path)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "# Add a new image not belonging to dataset\n",
    "emb = get_dino_embedding(IMG_PATH)\n",
    "embeddings.append(emb)\n",
    "\n",
    "embeddings = np.vstack(embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE dimensionality reduction on the vector representations\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the thumbnail images\n",
    "images = []\n",
    "\n",
    "# Iterate over all files in the directory specified by PATH\n",
    "for image in tqdm(image_paths):\n",
    "    # Open each image file\n",
    "    I = Image.open(image)\n",
    "\n",
    "    # Resize the image to a thumbnail size of [100, 100] using Lanczos resampling\n",
    "    I.thumbnail([100, 100], Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Append the resized image to the images list\n",
    "    images.append(I)\n",
    "\n",
    "\n",
    "# Open the image 'cocacola.jpeg'\n",
    "I = Image.open(IMG_PATH)\n",
    "# Resize the image to a thumbnail size of [100, 100] using Lanczos resampling\n",
    "I.thumbnail([100, 100], Image.Resampling.LANCZOS)\n",
    "# Append the resized image to the imagenes list\n",
    "images.append(I)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot to visualize the t-SNE embeddings\n",
    "fig, ax = plt.subplots(figsize=(20, 16))\n",
    "scatter = ax.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1])\n",
    "\n",
    "# Call the function to display the images on the scatter plot\n",
    "show_images(embeddings_tsne[:, 0], embeddings_tsne[:, 1], images, ax)\n",
    "\n",
    "\n",
    "# Highlight the new added picture\n",
    "# Create an Ellipse patch with specified center, width, height, and angle\n",
    "ellipse = Ellipse(xy=embeddings_tsne[-1,:], width=0.6, height=1.6, angle=0, fill=False)\n",
    "# Add the Ellipse patch to the axes\n",
    "ax.add_patch(ellipse)\n",
    "\n",
    "# Set the title and labels for the plot\n",
    "ax.set_title('t-SNE')\n",
    "ax.set_xlabel('Dimension 1')\n",
    "ax.set_ylabel('Dimension 2')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
